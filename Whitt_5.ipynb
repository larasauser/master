{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1FjptXGONkQ9FHHFgxFun",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larasauser/master/blob/main/Whitt_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 0) Installer / importer libs et monter Drive ===\n",
        "!pip install rasterio tqdm scikit-image scikit-learn piq --quiet\n",
        "\n",
        "import os\n",
        "from glob import glob\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.warp import reproject, Resampling\n",
        "from scipy.linalg import lstsq\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import piq\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "id": "kuSByiP_iSd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 1) Paramètres principaux ===\n",
        "DRIVE_CLEAR_FOLDER = '/content/drive/MyDrive/Whitt/NDVI_herens_Landsat8'\n",
        "DRIVE_MASKED_FOLDER = '/content/drive/MyDrive/Whitt/NDVI_herens_Landsat8_holes'\n",
        "DRIVE_MODIS_FOLDER = '/content/drive/MyDrive/Whitt/NDVI_herens_MODIS'\n",
        "OUTPUT_FOLDER = '/content/drive/MyDrive/Whitt/egfwh_herens_outputs_optim'\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "WINDOW_METERS = 400.0  # Taille fenêtre pour pixels voisins MODIS\n",
        "MODIS_WINDOW_DAYS = 8   # +/- jours autour de chaque Landsat\n",
        "KAPPA = 5.0             # Whittaker smoothing\n",
        "MIN_OVERLAP = 3         # nb min de points valides pour corrélation\n"
      ],
      "metadata": {
        "id": "vnFIy856iUdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 2) Fonctions helpers ===\n",
        "def parse_date_from_filename(fn):\n",
        "    import re\n",
        "    m = re.search(r'(\\d{4})-(\\d{2})-(\\d{2})', os.path.basename(fn))\n",
        "    if m:\n",
        "        return datetime.strptime(''.join(m.groups()), '%Y%m%d').date()\n",
        "    return datetime.fromtimestamp(os.path.getmtime(fn)).date()\n",
        "\n",
        "def read_singleband_tif(path):\n",
        "    with rasterio.open(path) as src:\n",
        "        arr = src.read(1).astype(np.float32)\n",
        "        meta = src.meta.copy()\n",
        "    nd = meta.get('nodata', None)\n",
        "    if nd is not None:\n",
        "        arr[arr==nd] = np.nan\n",
        "    return arr, meta\n",
        "\n",
        "def resample_to_target(src_arr, src_meta, target_meta):\n",
        "    dst_arr = np.full((target_meta['height'], target_meta['width']), np.nan, dtype=np.float32)\n",
        "    reproject(\n",
        "        source=src_arr,\n",
        "        destination=dst_arr,\n",
        "        src_transform=src_meta['transform'],\n",
        "        src_crs=src_meta['crs'],\n",
        "        dst_transform=target_meta['transform'],\n",
        "        dst_crs=target_meta['crs'],\n",
        "        resampling=Resampling.bilinear\n",
        "    )\n",
        "    return dst_arr\n",
        "\n",
        "# === 3) Charger et aligner les images ===\n",
        "clear_files = sorted(glob(os.path.join(DRIVE_CLEAR_FOLDER, '*.tif')))\n",
        "masked_files = sorted(glob(os.path.join(DRIVE_MASKED_FOLDER, '*.tif')))\n",
        "modis_files = sorted(glob(os.path.join(DRIVE_MODIS_FOLDER, '*.tif')))\n",
        "\n",
        "# trouver la plus petite image Landsat pour référence\n",
        "sizes = []\n",
        "for f in clear_files:\n",
        "    arr, meta = read_singleband_tif(f)\n",
        "    sizes.append((arr.shape[0]*arr.shape[1], f, arr.shape, meta))\n",
        "sizes.sort()\n",
        "_, ref_file, ref_shape, ref_meta = sizes[0]\n",
        "H_ref, W_ref = ref_shape\n",
        "PIXEL_SIZE_M = abs(ref_meta['transform'][0])\n",
        "print(\"Reference Landsat:\", os.path.basename(ref_file), \"shape:\", ref_shape)\n",
        "\n",
        "# --- Stacks Landsat ---\n",
        "landsat_clear_stack, landsat_masked_stack = [], []\n",
        "clear_dates, masked_dates = [], []\n",
        "\n",
        "for f in clear_files:\n",
        "    arr, meta = read_singleband_tif(f)\n",
        "    if arr.shape != ref_shape:\n",
        "        arr = resample_to_target(arr, meta, ref_meta)\n",
        "    landsat_clear_stack.append(arr)\n",
        "    clear_dates.append(parse_date_from_filename(f))\n",
        "\n",
        "for f in masked_files:\n",
        "    arr, meta = read_singleband_tif(f)\n",
        "    if arr.shape != ref_shape:\n",
        "        arr = resample_to_target(arr, meta, ref_meta)\n",
        "    landsat_masked_stack.append(arr)\n",
        "    masked_dates.append(parse_date_from_filename(f))\n",
        "\n",
        "landsat_clear_stack = np.stack(landsat_clear_stack, axis=0)\n",
        "landsat_masked_stack = np.stack(landsat_masked_stack, axis=0)\n",
        "T, H, W = landsat_clear_stack.shape\n",
        "print(\"Stacks shapes (clear/masked):\", landsat_clear_stack.shape, landsat_masked_stack.shape)\n",
        "\n",
        "# === MODIS multi-image stack ===\n",
        "modis_map = {parse_date_from_filename(f): f for f in modis_files}\n",
        "modis_dates_list = sorted(modis_map.keys())\n",
        "\n",
        "modis_stack = np.full((T, H, W), np.nan, dtype=np.float32)\n",
        "for ti, d in enumerate(clear_dates):\n",
        "    # Sélection de toutes les MODIS dans +/- MODIS_WINDOW_DAYS\n",
        "    selected_modis = [md for md in modis_dates_list if abs((md - d).days) <= MODIS_WINDOW_DAYS]\n",
        "    if len(selected_modis) == 0:\n",
        "        continue\n",
        "    mod_arrs = []\n",
        "    for md in selected_modis:\n",
        "        arr, meta = read_singleband_tif(modis_map[md])\n",
        "        arr_resampled = resample_to_target(arr, meta, ref_meta)\n",
        "        mod_arrs.append(arr_resampled)\n",
        "    modis_stack[ti] = np.nanmean(np.stack(mod_arrs, axis=0), axis=0)\n",
        "\n",
        "print(\"MODIS stack aligned (multi-image):\", modis_stack.shape)\n"
      ],
      "metadata": {
        "id": "NUcH58SDiVLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 4) Helpers EGF / Whittaker ===\n",
        "def pearson_r(a, b):\n",
        "    valid = ~np.isnan(a) & ~np.isnan(b)\n",
        "    if valid.sum() < 2:\n",
        "        return np.nan\n",
        "    x, y = a[valid], b[valid]\n",
        "    xm, ym = x.mean(), y.mean()\n",
        "    num = np.sum((x - xm)*(y - ym))\n",
        "    den = np.sqrt(np.sum((x - xm)**2)*np.sum((y - ym)**2))\n",
        "    if den==0:\n",
        "        return np.nan\n",
        "    return num/den\n",
        "\n",
        "def compute_M_reference_pixel(i, j, modis_stack, sl_target_ts, radius_pix):\n",
        "    T, H, W = modis_stack.shape\n",
        "    i0, i1 = max(0, i - radius_pix), min(H, i + radius_pix + 1)\n",
        "    j0, j1 = max(0, j - radius_pix), min(W, j + radius_pix + 1)\n",
        "    coords = [(ii, jj) for ii in range(i0, i1) for jj in range(j0, j1)]\n",
        "\n",
        "    corrs, mseries = [], []\n",
        "    for ii, jj in coords:\n",
        "        ms = modis_stack[:, ii, jj]\n",
        "        r = pearson_r(ms, sl_target_ts)\n",
        "        if np.isnan(r) or r < 0.3:\n",
        "            continue\n",
        "        corrs.append(r)\n",
        "        mseries.append(ms)\n",
        "\n",
        "    if len(corrs) == 0:\n",
        "        return None\n",
        "\n",
        "    R = np.array(corrs)\n",
        "    ms_valid = np.array(mseries)\n",
        "\n",
        "    # Pondération par corrélation\n",
        "    R = (R - R.min()) / (R.max() - R.min()) if R.max() != R.min() else np.ones_like(R)\n",
        "    weights = R / R.sum()\n",
        "\n",
        "    Mref = np.zeros(T, dtype=float)\n",
        "    support = np.zeros(T, dtype=float)\n",
        "    for w, ms in zip(weights, ms_valid):\n",
        "        valid_t = ~np.isnan(ms)\n",
        "        Mref[valid_t] += w * ms[valid_t]\n",
        "        support[valid_t] += w\n",
        "    Mref[support==0] = np.nan\n",
        "    return Mref\n",
        "\n",
        "def estimate_linear_transfer(M_ref, SL_ts):\n",
        "    valid = ~np.isnan(M_ref) & ~np.isnan(SL_ts)\n",
        "    if valid.sum() < 2: return None\n",
        "    A = np.vstack([M_ref[valid], np.ones(valid.sum())]).T\n",
        "    y = SL_ts[valid]\n",
        "    sol, *_ = lstsq(A, y)\n",
        "    return sol[0], sol[1]\n",
        "\n",
        "def whittaker_smoother(y, kappa=5.0):\n",
        "    n = y.shape[0]\n",
        "    mask = ~np.isnan(y)\n",
        "    if mask.sum()==0: return np.full_like(y,np.nan)\n",
        "    out = np.full_like(y,np.nan,dtype=float)\n",
        "    idx = np.where(mask)[0]\n",
        "    runs = np.split(idx, np.where(np.diff(idx)!=1)[0]+1)\n",
        "    for run in runs:\n",
        "        s,e = run[0], run[-1]+1\n",
        "        seg = y[s:e].astype(float)\n",
        "        m = len(seg)\n",
        "        if m<=2: out[s:e]=seg; continue\n",
        "        D = np.zeros((m-2,m))\n",
        "        for r in range(m-2): D[r,r]=1; D[r,r+1]=-2; D[r,r+2]=1\n",
        "        A_mat = np.eye(m)+kappa*(D.T@D)\n",
        "        out[s:e] = np.linalg.solve(A_mat, seg)\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "EwU4nlhGiYGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 5) Reconstruction ===\n",
        "radius_pix = int(round((WINDOW_METERS / 2.0) / PIXEL_SIZE_M))\n",
        "A = np.full((H, W), np.nan)\n",
        "A0 = np.full((H, W), np.nan)\n",
        "Mref_stack = np.full((T, H, W), np.nan)\n",
        "\n",
        "print(\"Estimating M_reference and linear transfer for each pixel...\")\n",
        "for i in tqdm(range(H)):\n",
        "    for j in range(W):\n",
        "        sl_target_ts = landsat_clear_stack[:, i, j]\n",
        "        Mref = compute_M_reference_pixel(i, j, modis_stack, sl_target_ts, radius_pix)\n",
        "\n",
        "        if Mref is None:\n",
        "            # fallback: moyenne locale si pas de corrélation\n",
        "            i0, i1 = max(0, i - radius_pix), min(H, i + radius_pix + 1)\n",
        "            j0, j1 = max(0, j - radius_pix), min(W, j + radius_pix + 1)\n",
        "            block = modis_stack[:, i0:i1, j0:j1]\n",
        "            Mref = np.nanmean(block.reshape(T, -1), axis=1)\n",
        "\n",
        "        Mref_stack[:, i, j] = Mref\n",
        "        est = estimate_linear_transfer(Mref, sl_target_ts)\n",
        "        if est is not None:\n",
        "            A[i, j], A0[i, j] = est\n",
        "\n",
        "print(\"✅ M_reference and linear transfer computation done.\")\n",
        "\n",
        "# === 5.1 Reconstruction temporaire avec coefficients linéaires ===\n",
        "SLM = np.full((T, H, W), np.nan)\n",
        "for i in range(H):\n",
        "    for j in range(W):\n",
        "        if not np.isnan(A[i, j]) and not np.isnan(A0[i, j]):\n",
        "            SLM[:, i, j] = Mref_stack[:, i, j]*A[i, j] + A0[i, j]\n",
        "\n",
        "# === 5.2 Injection des valeurs reconstruites uniquement sur les gaps + Whittaker ===\n",
        "final_stack = landsat_masked_stack.copy()\n",
        "print(\"Merging reconstructed values into masked pixels and applying Whittaker smoothing...\")\n",
        "\n",
        "for t in range(len(masked_dates)):\n",
        "    gap_mask = np.isnan(final_stack[t])\n",
        "    smoothed_gap = np.full((H, W), np.nan)\n",
        "    for i in range(H):\n",
        "        for j in range(W):\n",
        "            if gap_mask[i, j]:\n",
        "                smoothed_gap[i, j] = whittaker_smoother(SLM[:, i, j], kappa=KAPPA)[t]\n",
        "    final_stack[t, gap_mask] = smoothed_gap[gap_mask]\n",
        "\n",
        "print(\"✅ Reconstruction + Whittaker smoothing applied\")\n"
      ],
      "metadata": {
        "id": "Q2A068_SiY7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 6.4 Fonction pour sauvegarder GeoTIFFs ===\n",
        "def write_tif_nan(path, arr, meta_template):\n",
        "    meta = meta_template.copy()\n",
        "    meta.update({'count': 1, 'dtype': 'float32', 'nodata': None})\n",
        "    with rasterio.open(path, 'w', **meta) as dst:\n",
        "        dst.write(arr.astype(np.float32), 1)\n",
        "\n",
        "# === 6.5 Export final ===\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "print(\"Saving reconstructed GeoTIFFs...\")\n",
        "for t, date in enumerate(masked_dates):\n",
        "    outpath = os.path.join(OUTPUT_FOLDER, f'recon_{date}.tif')\n",
        "    write_tif_nan(outpath, final_stack[t], ref_meta)\n",
        "    print(\"Saved\", outpath)\n",
        "\n",
        "print(\"✅ Finished. Reconstructions available in:\", OUTPUT_FOLDER)\n"
      ],
      "metadata": {
        "id": "JIG7PbuZijEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import numpy as np\n",
        "from rasterio.warp import reproject, Resampling\n",
        "import rasterio\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "# === Dossiers ===\n",
        "hole_dir = '/content/drive/MyDrive/Whitt/NDVI_herens_Landsat8_holes'\n",
        "gt_dir = '/content/drive/MyDrive/Whitt/NDVI_herens_full'\n",
        "recon_dir = '/content/drive/MyDrive/Whitt/egfwh_herens_outputs_multisource2'\n",
        "\n",
        "# === Liste des fichiers ===\n",
        "hole_files = sorted(glob(os.path.join(hole_dir, '*.tif')))\n",
        "gt_files = sorted(glob(os.path.join(gt_dir, '*.tif')))\n",
        "recon_files = sorted(glob(os.path.join(recon_dir, 'recon_*.tif')))\n",
        "\n",
        "# === Fonctions utilitaires ===\n",
        "def read_tif_with_meta(path):\n",
        "    with rasterio.open(path) as src:\n",
        "        arr = src.read(1).astype(np.float32)\n",
        "        meta = src.meta.copy()\n",
        "    arr[arr == meta.get('nodata', -9999)] = np.nan\n",
        "    return arr, meta\n",
        "\n",
        "def resample_to_match(source_arr, source_meta, target_meta):\n",
        "    dst_arr = np.empty((target_meta['height'], target_meta['width']), dtype=np.float32)\n",
        "    reproject(\n",
        "        source=source_arr,\n",
        "        destination=dst_arr,\n",
        "        src_transform=source_meta['transform'],\n",
        "        src_crs=source_meta['crs'],\n",
        "        dst_transform=target_meta['transform'],\n",
        "        dst_crs=target_meta['crs'],\n",
        "        resampling=Resampling.bilinear\n",
        "    )\n",
        "    return dst_arr\n",
        "\n",
        "# === Visualisation ===\n",
        "for i in range(len(hole_files)):\n",
        "    fname = os.path.basename(hole_files[i])\n",
        "    date = fname.replace('NDVI_', '').replace('.tif', '')\n",
        "\n",
        "    # Lecture de l'image trouée (référence)\n",
        "    hole, hole_meta = read_tif_with_meta(hole_files[i])\n",
        "\n",
        "    # Lecture et alignement des GT et reconstruction\n",
        "    gt, gt_meta = read_tif_with_meta(gt_files[i])\n",
        "    gt_resampled = resample_to_match(gt, gt_meta, hole_meta)\n",
        "\n",
        "    recon, recon_meta = read_tif_with_meta(recon_files[i])\n",
        "    recon_resampled = resample_to_match(recon, recon_meta, hole_meta)\n",
        "\n",
        "    # Crée un masque des gaps (NaN dans hole)\n",
        "    gap_mask = np.isnan(hole)\n",
        "\n",
        "    # Calcul de l'erreur uniquement sur les pixels des gaps\n",
        "    err = np.full_like(hole, np.nan)\n",
        "    valid_mask = gap_mask & ~np.isnan(gt_resampled) & ~np.isnan(recon_resampled)\n",
        "    err[valid_mask] = gt_resampled[valid_mask] - recon_resampled[valid_mask]\n",
        "    #err = gt_resampled - recon_resampled\n",
        "    # === Figure ===\n",
        "    fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
        "\n",
        "    # === Création d'une colormap grise avec NaN en rouge ===\n",
        "    cmap_gray_red = plt.cm.gray\n",
        "    cmap_gray_red.set_bad(color='red')  # NaN en rouge\n",
        "\n",
        "    # 1) GAP\n",
        "    axs[0].imshow(np.ma.masked_invalid(hole), cmap=cmap_gray_red, vmin=-1, vmax=1)\n",
        "    axs[0].set_title(f'GAP - {date}', fontweight='bold')\n",
        "    axs[0].axis('off')\n",
        "\n",
        "    # 2) GT\n",
        "    axs[1].imshow(np.ma.masked_invalid(gt_resampled), cmap=cmap_gray_red, vmin=-1, vmax=1)\n",
        "    axs[1].set_title(f'GT - {date}', fontweight='bold')\n",
        "    axs[1].axis('off')\n",
        "\n",
        "    # 3) Reconstruction\n",
        "    axs[2].imshow(np.ma.masked_invalid(recon_resampled), cmap=cmap_gray_red, vmin=-1, vmax=1)\n",
        "    axs[2].set_title(f'RE - {date}', fontweight='bold')\n",
        "    axs[2].axis('off')\n",
        "\n",
        "    # 4) Erreur (GT - RE)\n",
        "    im4 = axs[3].imshow(np.ma.masked_invalid(err), cmap='RdYlGn')\n",
        "    axs[3].set_title('ERR (GT - RE)', fontweight='bold')\n",
        "    axs[3].axis('off')\n",
        "    plt.colorbar(im4, ax=axs[3], fraction=0.046, pad=0.04)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "b_xje7PPjIQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "from rasterio.warp import reproject, Resampling\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import torch\n",
        "import piq\n",
        "from glob import glob\n",
        "\n",
        "# === Dossiers ===\n",
        "hole_dir = '/content/drive/MyDrive/Whitt/NDVI_herens_Landsat8_holes'\n",
        "gt_dir = '/content/drive/MyDrive/Whitt/NDVI_herens_full'\n",
        "recon_dir = '/content/drive/MyDrive/Whitt/egfwh_herens_outputs_multisource2'\n",
        "\n",
        "# === Liste des fichiers ===\n",
        "hole_files = sorted(glob(os.path.join(hole_dir, '*.tif')))\n",
        "gt_files = sorted(glob(os.path.join(gt_dir, '*.tif')))\n",
        "recon_files = sorted(glob(os.path.join(recon_dir, 'recon_*.tif')))\n",
        "\n",
        "# === Fonctions utilitaires ===\n",
        "def read_tif_with_meta(path):\n",
        "    with rasterio.open(path) as src:\n",
        "        arr = src.read(1).astype(np.float32)\n",
        "        meta = src.meta.copy()\n",
        "    arr[arr == meta.get('nodata', -9999)] = np.nan\n",
        "    return arr, meta\n",
        "\n",
        "def resample_to_match(source_arr, source_meta, target_meta):\n",
        "    \"\"\"Reprojette et recadre une image pour matcher une autre.\"\"\"\n",
        "    dst_arr = np.empty((target_meta['height'], target_meta['width']), dtype=np.float32)\n",
        "    reproject(\n",
        "        source=source_arr,\n",
        "        destination=dst_arr,\n",
        "        src_transform=source_meta['transform'],\n",
        "        src_crs=source_meta['crs'],\n",
        "        dst_transform=target_meta['transform'],\n",
        "        dst_crs=target_meta['crs'],\n",
        "        resampling=Resampling.bilinear\n",
        "    )\n",
        "    return dst_arr\n",
        "\n",
        "# === Fonction metrics ===\n",
        "def evaluate_metrics(gt_img, recon_img, gap_mask, image_name):\n",
        "    \"\"\"\n",
        "    Calcul des metrics uniquement sur les pixels manquants (gap_mask = True)\n",
        "    \"\"\"\n",
        "    valid_mask = gap_mask & ~np.isnan(gt_img) & ~np.isnan(recon_img)\n",
        "    if np.sum(valid_mask) == 0:\n",
        "        return pd.DataFrame([{\n",
        "            'Image name': image_name,\n",
        "            'RMSE': np.nan, 'R²': np.nan, 'MAE': np.nan,\n",
        "            'MS-SSIM': np.nan, '% reconstructed pixels': 0.0\n",
        "        }])\n",
        "\n",
        "    y_true = gt_img[valid_mask]\n",
        "    y_pred = recon_img[valid_mask]\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred) if np.var(y_true) > 1e-8 else np.nan\n",
        "    mae = np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "    # Normalisation pour MS-SSIM uniquement sur pixels valides\n",
        "    min_val = np.min([y_true.min(), y_pred.min()])\n",
        "    max_val = np.max([y_true.max(), y_pred.max()])\n",
        "    if max_val - min_val < 1e-8:\n",
        "        ms_ssim_score = np.nan\n",
        "    else:\n",
        "        gt_norm = (gt_img - min_val) / (max_val - min_val)\n",
        "        recon_norm = (recon_img - min_val) / (max_val - min_val)\n",
        "        gt_norm[~valid_mask] = 0.0\n",
        "        recon_norm[~valid_mask] = 0.0\n",
        "        gt_tensor = torch.from_numpy(gt_norm).unsqueeze(0).unsqueeze(0).float()\n",
        "        recon_tensor = torch.from_numpy(recon_norm).unsqueeze(0).unsqueeze(0).float()\n",
        "        ms_ssim_score = piq.multi_scale_ssim(gt_tensor, recon_tensor, data_range=1., reduction='none').item()\n",
        "\n",
        "    coverage = (np.sum(valid_mask) / np.sum(gap_mask)) * 100 if np.sum(gap_mask) > 0 else 0.0\n",
        "\n",
        "    results = {\n",
        "        'Image name': image_name,\n",
        "        'RMSE': rmse,\n",
        "        'R²': r2,\n",
        "        'MAE': mae,\n",
        "        'MS-SSIM': ms_ssim_score,\n",
        "        '% reconstructed pixels': coverage\n",
        "    }\n",
        "    return pd.DataFrame([results])\n",
        "\n",
        "# === Calcul des metrics pour toutes les images ===\n",
        "all_results = []\n",
        "\n",
        "for hole_path in hole_files:\n",
        "    fname = os.path.basename(hole_path)\n",
        "    date_str = fname.replace('NDVI_', '').replace('.tif', '')\n",
        "\n",
        "    # Lecture et alignement de l'image trouée\n",
        "    hole_img, hole_meta = read_tif_with_meta(hole_path)\n",
        "\n",
        "    # Ground truth\n",
        "    gt_path = [f for f in gt_files if date_str in f][0]\n",
        "    gt_img, gt_meta = read_tif_with_meta(gt_path)\n",
        "    gt_resampled = resample_to_match(gt_img, gt_meta, hole_meta)\n",
        "\n",
        "    # Reconstruction\n",
        "    recon_path = [f for f in recon_files if date_str in f][0]\n",
        "    recon_img, recon_meta = read_tif_with_meta(recon_path)\n",
        "    recon_resampled = resample_to_match(recon_img, recon_meta, hole_meta)\n",
        "\n",
        "    # Gap mask (pixels manquants dans l'image trouée)\n",
        "    gap_mask = np.isnan(hole_img)\n",
        "\n",
        "    # Metrics\n",
        "    df = evaluate_metrics(gt_resampled, recon_resampled, gap_mask, fname)\n",
        "    all_results.append(df)\n",
        "\n",
        "# Table finale\n",
        "metrics_table = pd.concat(all_results, ignore_index=True)\n",
        "metrics_table"
      ],
      "metadata": {
        "id": "Ult0PGbxjLiX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}