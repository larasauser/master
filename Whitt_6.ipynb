{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkyW7nn4M+I2REhO3Wn3FR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larasauser/master/blob/main/Whitt_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 0) Installer / importer libs et monter Drive ===\n",
        "!pip install rasterio tqdm scikit-image scikit-learn piq joblib --quiet\n",
        "\n",
        "import os\n",
        "import re\n",
        "from glob import glob\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.warp import reproject, Resampling\n",
        "from scipy.linalg import lstsq\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import piq\n",
        "from joblib import Parallel, delayed\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2a7IS2cx_mYd",
        "outputId": "e945ef25-eeb3-4264-9f35-d9fc40c5d8cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 1) Paramètres principaux ===\n",
        "DRIVE_CLEAR_FOLDER = '/content/drive/MyDrive/Whitt/NDVI_grancy_Landsat8'\n",
        "DRIVE_MASKED_FOLDER = '/content/drive/MyDrive/Whitt/NDVI_grancy_Landsat8_hole'\n",
        "DRIVE_MODIS_FOLDER = '/content/drive/MyDrive/Whitt/NDVI_grancy_MODIS'\n",
        "DRIVE_SENTINEL_FOLDER = '/content/drive/MyDrive/Whitt/NDVI_grancy_S2'\n",
        "OUTPUT_FOLDER = '/content/drive/MyDrive/Whitt/egfwh_grancy_outputs_ok'\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "WINDOW_METERS = 200.0   # Taille fenêtre pour pixels voisins\n",
        "MODIS_WINDOW_DAYS = 32  # ± jours autour de chaque Landsat\n",
        "KAPPA = 5.0             # Whittaker smoothing\n",
        "MIN_OVERLAP = 3         # nb min de points valides pour corrélation\n"
      ],
      "metadata": {
        "id": "gZG55s0n_nQJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 2) Fonctions helpers ===\n",
        "def parse_date_from_filename(fn):\n",
        "    m = re.search(r'(\\d{4}-\\d{2}-\\d{2})', os.path.basename(fn))\n",
        "    if m:\n",
        "        return datetime.strptime(m.group(1), '%Y-%m-%d').date()\n",
        "    return datetime.fromtimestamp(os.path.getmtime(fn)).date()\n",
        "\n",
        "def read_singleband_tif(path):\n",
        "    with rasterio.open(path) as src:\n",
        "        arr = src.read(1).astype(np.float32)\n",
        "        meta = src.meta.copy()\n",
        "    nd = meta.get('nodata', None)\n",
        "    if nd is not None:\n",
        "        arr[arr==nd] = np.nan\n",
        "    return arr, meta\n",
        "\n",
        "def resample_to_reference(src_arr, src_meta, target_meta):\n",
        "    dst_arr = np.full((target_meta['height'], target_meta['width']), np.nan, dtype=np.float32)\n",
        "    reproject(\n",
        "        source=src_arr,\n",
        "        destination=dst_arr,\n",
        "        src_transform=src_meta['transform'],\n",
        "        src_crs=src_meta['crs'],\n",
        "        dst_transform=target_meta['transform'],\n",
        "        dst_crs=target_meta['crs'],\n",
        "        resampling=Resampling.bilinear\n",
        "    )\n",
        "    return dst_arr\n",
        "\n",
        "def pearson_r(a, b):\n",
        "    valid = ~np.isnan(a) & ~np.isnan(b)\n",
        "    if valid.sum() < 2: return np.nan\n",
        "    x, y = a[valid], b[valid]\n",
        "    xm, ym = x.mean(), y.mean()\n",
        "    num = np.sum((x - xm)*(y - ym))\n",
        "    den = np.sqrt(np.sum((x - xm)**2)*np.sum((y - ym)**2))\n",
        "    if den == 0: return np.nan\n",
        "    return num / den\n",
        "\n",
        "def estimate_linear_transfer(M_ref, SL_ts):\n",
        "    valid = ~np.isnan(M_ref) & ~np.isnan(SL_ts)\n",
        "    if valid.sum() < 2: return None\n",
        "    A = np.vstack([M_ref[valid], np.ones(valid.sum())]).T\n",
        "    y = SL_ts[valid]\n",
        "    sol, *_ = lstsq(A, y)\n",
        "    return sol[0], sol[1]\n",
        "\n",
        "def whittaker_smoother(y, kappa=5.0):\n",
        "    n = y.shape[0]\n",
        "    mask = ~np.isnan(y)\n",
        "    if mask.sum()==0: return np.full_like(y,np.nan)\n",
        "    out = np.full_like(y,np.nan,dtype=float)\n",
        "    idx = np.where(mask)[0]\n",
        "    runs = np.split(idx, np.where(np.diff(idx)!=1)[0]+1)\n",
        "    for run in runs:\n",
        "        s,e = run[0], run[-1]+1\n",
        "        seg = y[s:e].astype(float)\n",
        "        m = len(seg)\n",
        "        if m<=2: out[s:e]=seg; continue\n",
        "        D = np.zeros((m-2,m))\n",
        "        for r in range(m-2): D[r,r]=1; D[r,r+1]=-2; D[r,r+2]=1\n",
        "        A_mat = np.eye(m)+kappa*(D.T@D)\n",
        "        out[s:e] = np.linalg.solve(A_mat, seg)\n",
        "    return out"
      ],
      "metadata": {
        "id": "5dhHoT7__15P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 3) Charger Sentinel-2 comme référence ===\n",
        "sentinel_files = sorted(glob(os.path.join(DRIVE_SENTINEL_FOLDER, '*.tif')))\n",
        "sentinel_dates = [parse_date_from_filename(f) for f in sentinel_files]\n",
        "\n",
        "# Charger Sentinel-2 et définir la grille référence\n",
        "sentinel_stack = Parallel(n_jobs=-1)(\n",
        "    delayed(lambda f: read_singleband_tif(f)[0])(f) for f in tqdm(sentinel_files)\n",
        ")\n",
        "with rasterio.open(sentinel_files[0]) as src:\n",
        "    ref_meta = src.meta.copy()\n",
        "    H_ref, W_ref = src.height, src.width\n",
        "PIXEL_SIZE_M = abs(ref_meta['transform'][0])\n",
        "sentinel_stack = np.stack(sentinel_stack, axis=0)"
      ],
      "metadata": {
        "id": "1omFkKdLACVz",
        "outputId": "88d70ee4-27f2-4bea-cc5e-081cc47f7456",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 216/216 [00:39<00:00,  5.42it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 4) Charger et resampler Landsat et MODIS vers grille Sentinel-2 ===\n",
        "def load_and_resample_stack(files, dates, ref_meta):\n",
        "    stack = []\n",
        "    for f in files:\n",
        "        arr, meta = read_singleband_tif(f)\n",
        "        if arr.shape != (ref_meta['height'], ref_meta['width']):\n",
        "            arr = resample_to_reference(arr, meta, ref_meta)\n",
        "        stack.append(arr)\n",
        "    stack = np.stack(stack, axis=0)\n",
        "    return stack, dates\n",
        "\n",
        "clear_files = sorted(glob(os.path.join(DRIVE_CLEAR_FOLDER, '*.tif')))\n",
        "masked_files = sorted(glob(os.path.join(DRIVE_MASKED_FOLDER, '*.tif')))\n",
        "clear_dates = [parse_date_from_filename(f) for f in clear_files]\n",
        "masked_dates = [parse_date_from_filename(f) for f in masked_files]\n",
        "all_dates = sorted(list(set(clear_dates + masked_dates)))\n",
        "\n",
        "landsat_clear_stack, _ = load_and_resample_stack(clear_files, clear_dates, ref_meta)\n",
        "landsat_masked_stack, _ = load_and_resample_stack(masked_files, masked_dates, ref_meta)\n",
        "\n",
        "modis_files = sorted(glob(os.path.join(DRIVE_MODIS_FOLDER, '*.tif')))\n",
        "modis_dates = [parse_date_from_filename(f) for f in modis_files]\n",
        "modis_stack_full = Parallel(n_jobs=-1)(\n",
        "    delayed(lambda f: resample_to_reference(*read_singleband_tif(f), ref_meta))(f)\n",
        "    for f in tqdm(modis_files)\n",
        ")\n",
        "modis_stack_full = np.stack(modis_stack_full, axis=0)"
      ],
      "metadata": {
        "id": "flXa_acuAHcK",
        "outputId": "aebf7754-0de4-4169-b7ef-e6bb4c0df50e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 493/493 [00:31<00:00, 15.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === 5) Construire stack Landsat complet sur timeline ===\n",
        "ndvi_stack = np.full((len(all_dates), H_ref, W_ref), np.nan, dtype=np.float32)\n",
        "for i, date in enumerate(all_dates):\n",
        "    if date in clear_dates:\n",
        "        idx = clear_dates.index(date)\n",
        "        ndvi_stack[i] = landsat_clear_stack[idx]\n",
        "    elif date in masked_dates:\n",
        "        idx = masked_dates.index(date)\n",
        "        ndvi_stack[i] = landsat_masked_stack[idx]"
      ],
      "metadata": {
        "id": "WZbdoRgxATLF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Paramètres ===\n",
        "radius_pix = int(round(WINDOW_METERS / 2 / PIXEL_SIZE_M))\n",
        "Mref_stack = np.full((len(all_dates), H_ref, W_ref), np.nan, dtype=np.float32)\n",
        "A = np.full((H_ref, W_ref), np.nan, dtype=np.float32)\n",
        "A0 = np.full((H_ref, W_ref), np.nan, dtype=np.float32)\n",
        "\n",
        "# === Fonction sécurisée M_ref ===\n",
        "def compute_M_reference_pixel(i, j, landsat_ts, all_dates,\n",
        "                              modis_stack, modis_dates,\n",
        "                              sentinel_stack, sentinel_dates,\n",
        "                              radius_pix=3, corr_thresh=0.3, window_days=32):\n",
        "    T = len(all_dates)\n",
        "    Mref = np.full(T, np.nan)\n",
        "\n",
        "    for t, landsat_date in enumerate(all_dates):\n",
        "        # Dates MODIS/Sentinel proches\n",
        "        modis_idx = [k for k, d in enumerate(modis_dates) if abs((d - landsat_date).days) <= window_days]\n",
        "        sentinel_idx = [k for k, d in enumerate(sentinel_dates) if abs((d - landsat_date).days) <= window_days]\n",
        "\n",
        "        if len(modis_idx) == 0 and len(sentinel_idx) == 0:\n",
        "            continue\n",
        "\n",
        "        # Pixels voisins\n",
        "        i0, i1 = max(0, i - radius_pix), min(modis_stack.shape[1], i + radius_pix + 1)\n",
        "        j0, j1 = max(0, j - radius_pix), min(modis_stack.shape[2], j + radius_pix + 1)\n",
        "\n",
        "        values, corrs = [], []\n",
        "\n",
        "        # MODIS\n",
        "        for k in modis_idx:\n",
        "            block = modis_stack[k, i0:i1, j0:j1].reshape(-1)\n",
        "            valid = ~np.isnan(block) & ~np.isnan(landsat_ts[t])\n",
        "            if valid.sum() < MIN_OVERLAP:\n",
        "                continue\n",
        "            r = pearson_r(block, np.full_like(block, landsat_ts[t]))\n",
        "            if r >= corr_thresh:\n",
        "                values.append(np.nanmean(block))\n",
        "                corrs.append(r)\n",
        "\n",
        "        # Sentinel\n",
        "        for k in sentinel_idx:\n",
        "            block = sentinel_stack[k, i0:i1, j0:j1].reshape(-1)\n",
        "            valid = ~np.isnan(block) & ~np.isnan(landsat_ts[t])\n",
        "            if valid.sum() < MIN_OVERLAP:\n",
        "                continue\n",
        "            r = pearson_r(block, np.full_like(block, landsat_ts[t]))\n",
        "            if r >= corr_thresh:\n",
        "                values.append(np.nanmean(block))\n",
        "                corrs.append(r)\n",
        "\n",
        "        if len(values) > 0:\n",
        "            corrs = np.array(corrs)\n",
        "            weights = (corrs - corrs.min()) / (corrs.max() - corrs.min()) if corrs.max() != corrs.min() else np.ones_like(corrs)\n",
        "            weights /= weights.sum()\n",
        "            Mref[t] = np.sum(np.array(values) * weights)\n",
        "\n",
        "    return Mref"
      ],
      "metadata": {
        "id": "wGfw1aZ4AfFl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Fonction pixel pour calcul parallèle ===\n",
        "def process_pixel(i,j):\n",
        "    landsat_ts = ndvi_stack[:, i, j]\n",
        "    Mref = compute_M_reference_pixel(i, j, landsat_ts, all_dates,\n",
        "                                     modis_stack_full, modis_dates,\n",
        "                                     sentinel_stack, sentinel_dates,\n",
        "                                     radius_pix=radius_pix,\n",
        "                                     corr_thresh=0.3,\n",
        "                                     window_days=MODIS_WINDOW_DAYS)\n",
        "    est = estimate_linear_transfer(Mref, landsat_ts)\n",
        "    return i, j, Mref, est\n",
        "\n",
        "# === Calcul parallèle ===\n",
        "results = Parallel(n_jobs=-1, verbose=10)(\n",
        "    delayed(process_pixel)(i,j) for i in range(H_ref) for j in range(W_ref)\n",
        ")\n",
        "\n",
        "# === Remplir stacks ===\n",
        "for i,j,Mref,est in results:\n",
        "    Mref_stack[:, i, j] = Mref\n",
        "    if est is not None:\n",
        "        A[i,j], A0[i,j] = est"
      ],
      "metadata": {
        "id": "-E5rEUoSAuD_",
        "outputId": "17cbab8a-a7f8-4fe3-cc2e-db169e1a708e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.7s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    4.1s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    5.1s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    6.0s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    8.1s\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   10.0s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   12.2s\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   13.8s\n",
            "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:   16.0s\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:   18.0s\n",
            "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   22.4s\n",
            "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:   26.7s\n",
            "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:   31.6s\n",
            "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:   34.9s\n",
            "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:   41.6s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:   45.6s\n",
            "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:   49.9s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   56.0s\n",
            "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=-1)]: Done 238 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done 261 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=-1)]: Done 309 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=-1)]: Done 334 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=-1)]: Done 417 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=-1)]: Done 477 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=-1)]: Done 541 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done 574 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=-1)]: Done 609 tasks      | elapsed:  2.5min\n",
            "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=-1)]: Done 681 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=-1)]: Done 718 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=-1)]: Done 757 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=-1)]: Done 837 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=-1)]: Done 878 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=-1)]: Done 921 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=-1)]: Done 964 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=-1)]: Done 1009 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=-1)]: Done 1054 tasks      | elapsed:  4.1min\n",
            "[Parallel(n_jobs=-1)]: Done 1101 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=-1)]: Done 1197 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=-1)]: Done 1246 tasks      | elapsed:  5.0min\n",
            "[Parallel(n_jobs=-1)]: Done 1297 tasks      | elapsed:  5.3min\n",
            "[Parallel(n_jobs=-1)]: Done 1348 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=-1)]: Done 1401 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=-1)]: Done 1454 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=-1)]: Done 1509 tasks      | elapsed:  6.1min\n",
            "[Parallel(n_jobs=-1)]: Done 1564 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=-1)]: Done 1621 tasks      | elapsed:  6.5min\n",
            "[Parallel(n_jobs=-1)]: Done 1678 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=-1)]: Done 1737 tasks      | elapsed:  6.9min\n",
            "[Parallel(n_jobs=-1)]: Done 1796 tasks      | elapsed:  7.1min\n",
            "[Parallel(n_jobs=-1)]: Done 1857 tasks      | elapsed:  7.3min\n",
            "[Parallel(n_jobs=-1)]: Done 1918 tasks      | elapsed:  7.5min\n",
            "[Parallel(n_jobs=-1)]: Done 1981 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=-1)]: Done 2044 tasks      | elapsed:  8.0min\n",
            "[Parallel(n_jobs=-1)]: Done 2109 tasks      | elapsed:  8.3min\n",
            "[Parallel(n_jobs=-1)]: Done 2174 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=-1)]: Done 2241 tasks      | elapsed:  8.9min\n",
            "[Parallel(n_jobs=-1)]: Done 2308 tasks      | elapsed:  9.2min\n",
            "[Parallel(n_jobs=-1)]: Done 2377 tasks      | elapsed:  9.4min\n",
            "[Parallel(n_jobs=-1)]: Done 2446 tasks      | elapsed:  9.7min\n",
            "[Parallel(n_jobs=-1)]: Done 2517 tasks      | elapsed:  9.9min\n",
            "[Parallel(n_jobs=-1)]: Done 2588 tasks      | elapsed: 10.2min\n",
            "[Parallel(n_jobs=-1)]: Done 2661 tasks      | elapsed: 10.4min\n",
            "[Parallel(n_jobs=-1)]: Done 2734 tasks      | elapsed: 10.7min\n",
            "[Parallel(n_jobs=-1)]: Done 2809 tasks      | elapsed: 10.9min\n",
            "[Parallel(n_jobs=-1)]: Done 2884 tasks      | elapsed: 11.2min\n",
            "[Parallel(n_jobs=-1)]: Done 2961 tasks      | elapsed: 11.5min\n",
            "[Parallel(n_jobs=-1)]: Done 3038 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=-1)]: Done 3117 tasks      | elapsed: 12.2min\n",
            "[Parallel(n_jobs=-1)]: Done 3196 tasks      | elapsed: 12.5min\n",
            "[Parallel(n_jobs=-1)]: Done 3277 tasks      | elapsed: 12.9min\n",
            "[Parallel(n_jobs=-1)]: Done 3358 tasks      | elapsed: 13.2min\n",
            "[Parallel(n_jobs=-1)]: Done 3441 tasks      | elapsed: 13.5min\n",
            "[Parallel(n_jobs=-1)]: Done 3524 tasks      | elapsed: 13.8min\n",
            "[Parallel(n_jobs=-1)]: Done 3609 tasks      | elapsed: 14.1min\n",
            "[Parallel(n_jobs=-1)]: Done 3694 tasks      | elapsed: 14.4min\n",
            "[Parallel(n_jobs=-1)]: Done 3781 tasks      | elapsed: 14.7min\n",
            "[Parallel(n_jobs=-1)]: Done 3868 tasks      | elapsed: 15.0min\n",
            "[Parallel(n_jobs=-1)]: Done 3957 tasks      | elapsed: 15.4min\n",
            "[Parallel(n_jobs=-1)]: Done 4046 tasks      | elapsed: 15.8min\n",
            "[Parallel(n_jobs=-1)]: Done 4137 tasks      | elapsed: 16.2min\n",
            "[Parallel(n_jobs=-1)]: Done 4228 tasks      | elapsed: 16.6min\n",
            "[Parallel(n_jobs=-1)]: Done 4321 tasks      | elapsed: 17.0min\n",
            "[Parallel(n_jobs=-1)]: Done 4414 tasks      | elapsed: 17.3min\n",
            "[Parallel(n_jobs=-1)]: Done 4509 tasks      | elapsed: 17.7min\n",
            "[Parallel(n_jobs=-1)]: Done 4604 tasks      | elapsed: 18.0min\n",
            "[Parallel(n_jobs=-1)]: Done 4701 tasks      | elapsed: 18.3min\n",
            "[Parallel(n_jobs=-1)]: Done 4798 tasks      | elapsed: 18.7min\n",
            "[Parallel(n_jobs=-1)]: Done 4897 tasks      | elapsed: 19.1min\n",
            "[Parallel(n_jobs=-1)]: Done 4996 tasks      | elapsed: 19.5min\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3889689809.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# === Calcul parallèle ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m results = Parallel(n_jobs=-1, verbose=10)(\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_pixel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH_ref\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Reconstruction Landsat sur timeline ===\n",
        "SLM_stack = np.full_like(Mref_stack, np.nan, dtype=np.float32)\n",
        "for i in range(H_ref):\n",
        "    for j in range(W_ref):\n",
        "        if not np.isnan(A[i,j]) and not np.isnan(A0[i,j]):\n",
        "            SLM_stack[:, i, j] = Mref_stack[:, i,j]*A[i,j] + A0[i,j]"
      ],
      "metadata": {
        "id": "UiRdO6HKBKK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Injection des valeurs reconstruites dans les gaps + Whittaker smoothing ===\n",
        "final_stack = ndvi_stack.copy()\n",
        "for t, date in enumerate(all_dates):\n",
        "    gap_mask = np.isnan(final_stack[t])\n",
        "    smoothed_gap = np.full((H_ref, W_ref), np.nan)\n",
        "    for i in range(H_ref):\n",
        "        for j in range(W_ref):\n",
        "            if gap_mask[i,j]:\n",
        "                smoothed_gap[i,j] = whittaker_smoother(SLM_stack[:, i,j], kappa=KAPPA)[t]\n",
        "    final_stack[t, gap_mask] = smoothed_gap[gap_mask]"
      ],
      "metadata": {
        "id": "N9n65E-SBM7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_tif_nan(path, arr, meta_template):\n",
        "    \"\"\"\n",
        "    Sauvegarde un array 2D en GeoTIFF, avec NaN conservés.\n",
        "    \"\"\"\n",
        "    meta = meta_template.copy()\n",
        "    meta.update({\n",
        "        'count': 1,\n",
        "        'dtype': 'float32',\n",
        "        'nodata': None  # on laisse les NaN tels quels\n",
        "    })\n",
        "    with rasterio.open(path, 'w', **meta) as dst:\n",
        "        dst.write(arr.astype(np.float32), 1)"
      ],
      "metadata": {
        "id": "z_2gzMI6C6Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Sauvegarde GeoTIFFs ===\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "for t, date in enumerate(all_dates):\n",
        "    outpath = os.path.join(OUTPUT_FOLDER, f'recon_{date}.tif')\n",
        "    write_tif_nan(outpath, final_stack[t], ref_meta)\n",
        "    print(\"Saved\", outpath)\n",
        "\n",
        "print(\"✅ Reconstruction complète avec Sentinel-2 et parallélisation terminée.\")"
      ],
      "metadata": {
        "id": "hdHNNZnEBPB1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}