{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMIi1GbOEIRYFKKWP2pFkDh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larasauser/master/blob/main/Whitt_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "9xubtfkBOPga",
        "outputId": "2d5fc7dd-c86b-4da6-fd95-9dc94ae564ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov  3 10:18:06 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio tqdm scikit-image scikit-learn --quiet\n",
        "\n",
        "import os\n",
        "from glob import glob\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.warp import reproject, Resampling\n",
        "from scipy.linalg import lstsq\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "X0v5yvX5galx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 1) Dossiers Google Drive ===\n",
        "DRIVE_L8_FOLDER = '/content/drive/MyDrive/Whitt/NDVI_herens_Landsat8'\n",
        "DRIVE_S2_FOLDER = '/content/drive/MyDrive/Whitt/NDVI_herens_Sentinel2'\n",
        "DRIVE_MODIS_FOLDER = '/content/drive/MyDrive/Whitt/NDVI_herens_MODIS'\n",
        "DRIVE_MASKED_FOLDER = '/content/drive/MyDrive/Whitt/NDVI_herens_Landsat8_holes'\n",
        "OUTPUT_FOLDER = '/content/drive/MyDrive/Whitt/egfwh_herens_outputs_multisource'\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "# === 2) Paramètres globaux ===\n",
        "WINDOW_METERS = 400.0\n",
        "KAPPA = 5.0  # Paramètre du filtre Whittaker\n",
        "MIN_OVERLAP = 3"
      ],
      "metadata": {
        "id": "xroxv9YMgjvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_date_from_filename(fn):\n",
        "    import re\n",
        "    m = re.search(r'(\\d{4})-(\\d{2})-(\\d{2})', os.path.basename(fn))\n",
        "    if m:\n",
        "        return datetime.strptime('-'.join(m.groups()), '%Y-%m-%d').date()\n",
        "    return datetime.fromtimestamp(os.path.getmtime(fn)).date()\n",
        "\n",
        "def read_singleband_tif(path):\n",
        "    with rasterio.open(path) as src:\n",
        "        arr = src.read(1).astype(np.float32)\n",
        "        meta = src.meta.copy()\n",
        "    nd = meta.get('nodata', None)\n",
        "    if nd is not None:\n",
        "        arr[arr == nd] = np.nan\n",
        "    return arr, meta\n",
        "\n",
        "def resample_to_target(src_arr, src_meta, target_meta):\n",
        "    dst_arr = np.full((target_meta['height'], target_meta['width']), np.nan, dtype=np.float32)\n",
        "    reproject(\n",
        "        source=src_arr,\n",
        "        destination=dst_arr,\n",
        "        src_transform=src_meta['transform'],\n",
        "        src_crs=src_meta['crs'],\n",
        "        dst_transform=target_meta['transform'],\n",
        "        dst_crs=target_meta['crs'],\n",
        "        resampling=Resampling.bilinear\n",
        "    )\n",
        "    return dst_arr"
      ],
      "metadata": {
        "id": "XnZ6z6BMgmBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Chargement des fichiers ===\n",
        "landsat_files = sorted(glob(os.path.join(DRIVE_L8_FOLDER, '*.tif')))\n",
        "sentinel_files = sorted(glob(os.path.join(DRIVE_S2_FOLDER, '*.tif')))\n",
        "modis_files = sorted(glob(os.path.join(DRIVE_MODIS_FOLDER, '*.tif')))\n",
        "masked_files = sorted(glob(os.path.join(DRIVE_MASKED_FOLDER, '*.tif')))\n",
        "\n",
        "# --- Choisir Landsat comme référence spatiale ---\n",
        "ref_arr, ref_meta = read_singleband_tif(landsat_files[0])\n",
        "H_ref, W_ref = ref_arr.shape\n",
        "PIXEL_SIZE_M = abs(ref_meta['transform'][0])\n",
        "print(\"Référence Landsat:\", landsat_files[0], \"shape:\", (H_ref, W_ref))\n",
        "\n",
        "# --- Charger Landsat ---\n",
        "landsat_stack, landsat_dates = [], []\n",
        "for f in landsat_files:\n",
        "    arr, meta = read_singleband_tif(f)\n",
        "    if arr.shape != (H_ref, W_ref):\n",
        "        arr = resample_to_target(arr, meta, ref_meta)\n",
        "    landsat_stack.append(arr)\n",
        "    landsat_dates.append(parse_date_from_filename(f))\n",
        "landsat_stack = np.stack(landsat_stack)\n",
        "\n",
        "# --- Charger Sentinel-2 ---\n",
        "sentinel_stack, sentinel_dates = [], []\n",
        "for f in sentinel_files:\n",
        "    arr, meta = read_singleband_tif(f)\n",
        "    if arr.shape != (H_ref, W_ref):\n",
        "        arr = resample_to_target(arr, meta, ref_meta)\n",
        "    sentinel_stack.append(arr)\n",
        "    sentinel_dates.append(parse_date_from_filename(f))\n",
        "sentinel_stack = np.stack(sentinel_stack)\n",
        "\n",
        "# --- Fusion Landsat/Sentinel par Maximum Value Composite (MVC) ---\n",
        "T = min(len(landsat_dates), len(sentinel_dates))\n",
        "SL_stack = np.nanmax(np.stack([landsat_stack[:T], sentinel_stack[:T]]), axis=0)\n",
        "SL_dates = landsat_dates[:T]\n",
        "print(\"SL-NDVI fusionné:\", SL_stack.shape)\n",
        "\n",
        "# --- Alignement MODIS ---\n",
        "modis_stack = np.full_like(SL_stack, np.nan)\n",
        "modis_map = {parse_date_from_filename(f): f for f in modis_files}\n",
        "modis_dates_list = sorted(modis_map.keys())\n",
        "\n",
        "for ti, d in enumerate(SL_dates):\n",
        "    diffs = [(abs((md - d).days), md) for md in modis_dates_list]\n",
        "    nearest_md = min(diffs, key=lambda x: x[0])[1]\n",
        "    mod_file = modis_map[nearest_md]\n",
        "    arr, meta = read_singleband_tif(mod_file)\n",
        "    arr_resampled = resample_to_target(arr, meta, ref_meta)\n",
        "    modis_stack[ti] = arr_resampled\n",
        "\n",
        "print(\"MODIS aligné:\", modis_stack.shape)"
      ],
      "metadata": {
        "id": "3yjeZ7LYgm6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pearson_r(a, b):\n",
        "    valid = ~np.isnan(a) & ~np.isnan(b)\n",
        "    if valid.sum() < 2: return np.nan\n",
        "    x, y = a[valid], b[valid]\n",
        "    xm, ym = x.mean(), y.mean()\n",
        "    num = np.sum((x - xm) * (y - ym))\n",
        "    den = np.sqrt(np.sum((x - xm)**2) * np.sum((y - ym)**2))\n",
        "    return num / den if den != 0 else np.nan\n",
        "\n",
        "def compute_M_reference_pixel(i, j, modis_stack, sl_target_ts, radius_pix, corr_threshold=0.3):\n",
        "    T, H, W = modis_stack.shape\n",
        "    i0, i1 = max(0, i - radius_pix), min(H, i + radius_pix + 1)\n",
        "    j0, j1 = max(0, j - radius_pix), min(W, j + radius_pix + 1)\n",
        "\n",
        "    corrs, mseries = [], []\n",
        "    for ii in range(i0, i1):\n",
        "        for jj in range(j0, j1):\n",
        "            ms = modis_stack[:, ii, jj]\n",
        "            r = pearson_r(ms, sl_target_ts)\n",
        "            if not np.isnan(r) and r > corr_threshold:\n",
        "                corrs.append(r)\n",
        "                mseries.append(ms)\n",
        "\n",
        "    if len(corrs) == 0: return None\n",
        "\n",
        "    R = np.array(corrs)\n",
        "    ms_valid = np.array(mseries)\n",
        "    R = (R - R.min()) / (R.max() - R.min()) if R.max() != R.min() else np.ones_like(R)\n",
        "    weights = R / R.sum()\n",
        "\n",
        "    Mref = np.zeros(T)\n",
        "    support = np.zeros(T)\n",
        "    for w, ms in zip(weights, ms_valid):\n",
        "        valid_t = ~np.isnan(ms)\n",
        "        Mref[valid_t] += w * ms[valid_t]\n",
        "        support[valid_t] += w\n",
        "    Mref[support == 0] = np.nan\n",
        "    return Mref\n",
        "\n",
        "def estimate_linear_transfer(M_ref, SL_ts):\n",
        "    valid = ~np.isnan(M_ref) & ~np.isnan(SL_ts)\n",
        "    if valid.sum() < 2: return None\n",
        "    A = np.vstack([M_ref[valid], np.ones(valid.sum())]).T\n",
        "    y = SL_ts[valid]\n",
        "    sol, *_ = lstsq(A, y)\n",
        "    return sol[0], sol[1]\n",
        "\n",
        "def whittaker_smoother(y, kappa=5.0):\n",
        "    n = len(y)\n",
        "    mask = ~np.isnan(y)\n",
        "    if mask.sum() == 0: return np.full_like(y, np.nan)\n",
        "    out = np.full_like(y, np.nan)\n",
        "    idx = np.where(mask)[0]\n",
        "    runs = np.split(idx, np.where(np.diff(idx) != 1)[0] + 1)\n",
        "    for run in runs:\n",
        "        s, e = run[0], run[-1] + 1\n",
        "        seg = y[s:e]\n",
        "        m = len(seg)\n",
        "        if m <= 2:\n",
        "            out[s:e] = seg\n",
        "            continue\n",
        "        D = np.zeros((m - 2, m))\n",
        "        for r in range(m - 2): D[r, r:r+3] = [1, -2, 1]\n",
        "        A_mat = np.eye(m) + kappa * (D.T @ D)\n",
        "        out[s:e] = np.linalg.solve(A_mat, seg)\n",
        "    return out"
      ],
      "metadata": {
        "id": "qGOWQcoygpvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === 6) EGF full execution + Whittaker smoothing ONLY on gaps + export ===\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import rasterio\n",
        "\n",
        "# --- Safety checks (adapt if variable names differ) ---\n",
        "# SL_stack : (T, H, W) fused Landsat/Sentinel NDVI (SL-NDVI)\n",
        "# SL_dates : list of datetime.date for each SL_stack slice\n",
        "# modis_stack : (T, H, W) MODIS NDVI aligned to SL_dates\n",
        "# masked_files : list of masked Landsat paths (with NaNs for gaps)\n",
        "# ref_meta : rasterio meta of reference grid (Landsat)\n",
        "\n",
        "assert 'SL_stack' in globals(), \"SL_stack not found. Exécute le bloc de chargement/fusion (Bloc 4).\"\n",
        "assert 'modis_stack' in globals(), \"modis_stack not found. Exécute l'alignement MODIS (Bloc 4).\"\n",
        "assert 'ref_meta' in globals(), \"ref_meta not found. Charge une image de référence Landsat.\"\n",
        "\n",
        "T, H, W = SL_stack.shape\n",
        "print(\"T,H,W =\", T, H, W)\n",
        "\n",
        "# --- Make sure we have a landsat_masked_stack aligned to ref_meta (load if needed) ---\n",
        "# If landsat_masked_stack already exists from previous blocks, keep it; else build it now.\n",
        "if 'landsat_masked_stack' not in globals():\n",
        "    print(\"Building landsat_masked_stack from masked_files (resampling to reference)...\")\n",
        "    landsat_masked_stack = []\n",
        "    masked_dates = []\n",
        "    for f in masked_files:\n",
        "        arr, meta = read_singleband_tif(f)\n",
        "        if arr.shape != (H, W):\n",
        "            arr = resample_to_target(arr, meta, ref_meta)\n",
        "        landsat_masked_stack.append(arr)\n",
        "        masked_dates.append(parse_date_from_filename(f))\n",
        "    landsat_masked_stack = np.stack(landsat_masked_stack, axis=0)\n",
        "    print(\"landsat_masked_stack shape:\", landsat_masked_stack.shape)\n",
        "else:\n",
        "    masked_dates = [parse_date_from_filename(os.path.basename(p)) if isinstance(p, str) else None for p in masked_files]\n",
        "\n",
        "# --- 6.1) Estimate M_ref, A, A0 for each pixel ---\n",
        "radius_pix = int(round((WINDOW_METERS / 2.0) / PIXEL_SIZE_M))\n",
        "print(\"Window meters:\", WINDOW_METERS, \"-> radius_pix:\", radius_pix)\n",
        "\n",
        "A = np.full((H, W), np.nan, dtype=float)\n",
        "A0 = np.full((H, W), np.nan, dtype=float)\n",
        "Mref_stack = np.full((T, H, W), np.nan, dtype=float)\n",
        "\n",
        "print(\"Estimating M_reference and linear transfer per pixel (this may take time)...\")\n",
        "for i in tqdm(range(H), desc='rows'):\n",
        "    for j in range(W):\n",
        "        sl_target_ts = SL_stack[:, i, j]              # SL-NDVI time series for pixel\n",
        "        Mref = compute_M_reference_pixel(i, j, modis_stack, sl_target_ts, radius_pix, corr_threshold=0.3)\n",
        "        if Mref is None:\n",
        "            # fallback: local mean in window (use only valid MODIS values)\n",
        "            i0, i1 = max(0, i - radius_pix), min(H, i + radius_pix + 1)\n",
        "            j0, j1 = max(0, j - radius_pix), min(W, j + radius_pix + 1)\n",
        "            block = modis_stack[:, i0:i1, j0:j1]         # shape (T, nrows, ncols)\n",
        "            if np.all(np.isnan(block)):\n",
        "                continue\n",
        "            Mref_alt = np.nanmean(block.reshape(T, -1), axis=1)\n",
        "            Mref = Mref_alt\n",
        "        Mref_stack[:, i, j] = Mref\n",
        "        est = estimate_linear_transfer(Mref, sl_target_ts)\n",
        "        if est is not None:\n",
        "            A[i, j], A0[i, j] = est\n",
        "\n",
        "# --- 6.2) Compute SLM (full but will be used only on gaps) ---\n",
        "print(\"Computing SLM = a * Mref + a0 ...\")\n",
        "SLM = np.full((T, H, W), np.nan, dtype=float)\n",
        "valid_a = ~np.isnan(A) & ~np.isnan(A0)\n",
        "inds = np.where(valid_a)\n",
        "for ii, jj in zip(inds[0], inds[1]):\n",
        "    # vectorized along time\n",
        "    SLM[:, ii, jj] = Mref_stack[:, ii, jj] * A[ii, jj] + A0[ii, jj]\n",
        "\n",
        "# --- 6.3) For each masked image: apply Whittaker per-gap pixel only and inject ---\n",
        "final_stack = landsat_masked_stack.copy()  # copy original masked images (NaN in gaps)\n",
        "print(\"Merging reconstructed values into masked pixels and applying Whittaker smoothing...\")\n",
        "\n",
        "# To accelerate: precompute per-pixel Whittaker once (only for pixels that have at least one gap in any masked image)\n",
        "# Build a boolean map of pixels that ever need reconstruction (appears as NaN in any masked image)\n",
        "need_recon_mask = np.any(np.isnan(final_stack), axis=0)  # shape (H,W)\n",
        "print(\"Pixels requiring reconstruction (ever):\", int(np.count_nonzero(need_recon_mask)), \"/\", H*W)\n",
        "\n",
        "# Precompute smoothed series for required pixels only (store as array T x H x W but fill only needed pixels)\n",
        "# We'll compute whittaker_smoother on SLM[:,i,j] where need_recon_mask[i,j] is True and valid SLM exists\n",
        "smoothed_series = np.full((T, H, W), np.nan, dtype=float)\n",
        "\n",
        "# Loop only over pixels that need recon\n",
        "coords = np.argwhere(need_recon_mask)\n",
        "for (i, j) in tqdm(coords, desc='pixels to smooth'):\n",
        "    series = SLM[:, i, j]\n",
        "    if np.all(np.isnan(series)):\n",
        "        continue\n",
        "    z = whittaker_smoother(series, kappa=KAPPA)\n",
        "    smoothed_series[:, i, j] = z\n",
        "\n",
        "# Now inject per masked date only into gaps\n",
        "for t in tqdm(range(final_stack.shape[0]), desc='masked images'):\n",
        "    gap_mask = np.isnan(final_stack[t])  # True where pixel missing\n",
        "    if not np.any(gap_mask):\n",
        "        continue\n",
        "    # Use smoothed_series at time t for those pixels (if available)\n",
        "    inject_vals = smoothed_series[t]\n",
        "    valid_inject = ~np.isnan(inject_vals) & gap_mask\n",
        "    final_stack[t, valid_inject] = inject_vals[valid_inject]\n",
        "\n",
        "# --- 6.4) Exporting reconstructed GeoTIFFs (preserve geo/meta) ---\n",
        "def write_tif_nan(path, arr, meta_template):\n",
        "    meta = meta_template.copy()\n",
        "    # Ensure typical fields are present\n",
        "    meta.update({'count': 1, 'dtype': 'float32', 'nodata': None})\n",
        "    with rasterio.open(path, 'w', **meta) as dst:\n",
        "        dst.write(arr.astype(np.float32), 1)\n",
        "\n",
        "EXPORT_FOLDER = OUTPUT_FOLDER\n",
        "os.makedirs(EXPORT_FOLDER, exist_ok=True)\n",
        "print(\"Saving reconstructed GeoTIFFs to\", EXPORT_FOLDER)\n",
        "\n",
        "# masked_dates: if masked_dates are datetime.date objects, convert to isoformat for filenames\n",
        "try:\n",
        "    date_names = [d.isoformat() if hasattr(d, 'isoformat') else str(d) for d in masked_dates]\n",
        "except Exception:\n",
        "    date_names = [str(d) for d in masked_dates]\n",
        "\n",
        "for t, name in enumerate(date_names):\n",
        "    outpath = os.path.join(EXPORT_FOLDER, f'recon_{name}.tif')\n",
        "    write_tif_nan(outpath, final_stack[t], ref_meta)\n",
        "    print(\"Saved\", outpath)\n",
        "\n",
        "print(\"✅ Finished. Reconstructions and exports in:\", EXPORT_FOLDER)"
      ],
      "metadata": {
        "id": "RiEmsb28gsiu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}